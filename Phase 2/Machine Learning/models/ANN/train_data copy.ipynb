{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lucifrr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import joblib\n",
    "import re\n",
    "import nltk\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "# Unduh stopwords untuk Bahasa Indonesia\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopwords_indonesia = stopwords.words('indonesian')\n",
    "\n",
    "# Fungsi preprocessing\n",
    "def preprocess_text(text):\n",
    "    # Menghapus karakter yang tidak relevan dan menurunkan semua huruf menjadi kecil\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text.lower())\n",
    "    # Menghapus stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords_indonesia])\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah total data: 370\n",
      "Jumlah kelas unik: 74\n",
      "Adjusted test size: 0.2\n",
      "Distribusi kelas pada train set:\n",
      "33    4\n",
      "20    4\n",
      "44    4\n",
      "21    4\n",
      "31    4\n",
      "     ..\n",
      "16    4\n",
      "28    4\n",
      "43    4\n",
      "6     4\n",
      "56    4\n",
      "Name: count, Length: 74, dtype: int64\n",
      "\n",
      "Distribusi kelas pada test set:\n",
      "53    1\n",
      "26    1\n",
      "57    1\n",
      "33    1\n",
      "45    1\n",
      "     ..\n",
      "61    1\n",
      "16    1\n",
      "29    1\n",
      "22    1\n",
      "12    1\n",
      "Name: count, Length: 74, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project\\SoulBabble\\Phase 2\\Machine Learning\\venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['baiknya', 'berkali', 'kali', 'kurangnya', 'mata', 'olah', 'sekurang', 'setidak', 'tama', 'tidaknya'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Memuat data\n",
    "data = pd.read_csv('../../models/ANN/data_set.csv')\n",
    "\n",
    "# Membuat kolom 'Label' sebagai kombinasi dari 'Tipe_Emosi' dan 'Sumber_Emosi'\n",
    "data['Label'] = data['Tipe_Emosi'] + \"_\" + data['Sumber_Emosi']\n",
    "\n",
    "# Preprocessing teks\n",
    "data['Input_Text'] = data['Level_Emosi'] + \" \" + data['Tipe_Emosi'] + \" \" + data['Sumber_Emosi']\n",
    "data['Input_Text'] = data['Input_Text'].apply(preprocess_text)\n",
    "\n",
    "# Membuat mapping label ke pertanyaan\n",
    "label_to_questions = {}\n",
    "\n",
    "for idx, row in data.iterrows():\n",
    "    label = row['Label']\n",
    "    questions = [q.strip() for q in row['Pertanyaan_Analisis'].split('|')]\n",
    "    if label not in label_to_questions:\n",
    "        label_to_questions[label] = questions\n",
    "    else:\n",
    "        # Jika label sudah ada, pastikan hanya menyimpan 5 pertanyaan unik\n",
    "        existing_questions = set(label_to_questions[label])\n",
    "        for q in questions:\n",
    "            if q not in existing_questions and len(label_to_questions[label]) < 5:\n",
    "                label_to_questions[label].append(q)\n",
    "                existing_questions.add(q)\n",
    "\n",
    "# Pastikan setiap label memiliki 5 pertanyaan unik\n",
    "for label, questions in label_to_questions.items():\n",
    "    label_to_questions[label] = list(dict.fromkeys(questions))[:5]\n",
    "\n",
    "# Update TfidfVectorizer dan LabelEncoder\n",
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=2000, \n",
    "    ngram_range=(1, 2), \n",
    "    stop_words=stopwords_indonesia,\n",
    "    min_df=2  # Mengabaikan kata yang muncul kurang dari 2 kali\n",
    ")\n",
    "X = vectorizer.fit_transform(data['Input_Text']).toarray()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(data['Label'])\n",
    "\n",
    "# Periksa jumlah kelas dan total data\n",
    "print(f\"Jumlah total data: {len(data)}\")\n",
    "print(f\"Jumlah kelas unik: {len(set(y))}\")\n",
    "\n",
    "# Pastikan test_size cukup untuk jumlah kelas\n",
    "test_size = max(0.2, len(set(y)) / len(y))\n",
    "print(f\"Adjusted test size: {test_size}\")\n",
    "\n",
    "# Lakukan train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Periksa distribusi kelas pada train dan test set\n",
    "print(\"Distribusi kelas pada train set:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n",
    "print(\"\\nDistribusi kelas pada test set:\")\n",
    "print(pd.Series(y_test).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat model ANN yang disederhanakan\n",
    "def build_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Input(shape=(input_shape,)),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')  # Output layer\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        optimizer=Adam(learning_rate=1e-3),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 419ms/step - accuracy: 0.0000e+00 - loss: 4.3111\n",
      "Epoch 1: val_loss improved from inf to 4.26402, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.0035 - loss: 4.3049 - val_accuracy: 0.0676 - val_loss: 4.2640\n",
      "Epoch 2/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0000e+00 - loss: 4.2669\n",
      "Epoch 2: val_loss improved from 4.26402 to 4.20796, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.0813 - loss: 4.2503 - val_accuracy: 0.1757 - val_loss: 4.2080\n",
      "Epoch 3/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.0625 - loss: 4.2099\n",
      "Epoch 3: val_loss improved from 4.20796 to 4.12427, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.1874 - loss: 4.1899 - val_accuracy: 0.4324 - val_loss: 4.1243\n",
      "Epoch 4/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4375 - loss: 4.0927\n",
      "Epoch 4: val_loss improved from 4.12427 to 4.00122, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3532 - loss: 4.0920 - val_accuracy: 0.5270 - val_loss: 4.0012\n",
      "Epoch 5/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3125 - loss: 4.0286\n",
      "Epoch 5: val_loss improved from 4.00122 to 3.83381, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4185 - loss: 3.9501 - val_accuracy: 0.5676 - val_loss: 3.8338\n",
      "Epoch 6/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3125 - loss: 3.8673\n",
      "Epoch 6: val_loss improved from 3.83381 to 3.61836, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4660 - loss: 3.7887 - val_accuracy: 0.7297 - val_loss: 3.6184\n",
      "Epoch 7/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5625 - loss: 3.5742\n",
      "Epoch 7: val_loss improved from 3.61836 to 3.34049, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5786 - loss: 3.5536 - val_accuracy: 0.7838 - val_loss: 3.3405\n",
      "Epoch 8/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7500 - loss: 3.2587\n",
      "Epoch 8: val_loss improved from 3.34049 to 2.99979, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7013 - loss: 3.2309 - val_accuracy: 0.9054 - val_loss: 2.9998\n",
      "Epoch 9/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8125 - loss: 2.8360\n",
      "Epoch 9: val_loss improved from 2.99979 to 2.60173, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7940 - loss: 2.8657 - val_accuracy: 0.9595 - val_loss: 2.6017\n",
      "Epoch 10/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8750 - loss: 2.7014\n",
      "Epoch 10: val_loss improved from 2.60173 to 2.17290, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8799 - loss: 2.5681 - val_accuracy: 0.9865 - val_loss: 2.1729\n",
      "Epoch 11/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8125 - loss: 2.3835\n",
      "Epoch 11: val_loss improved from 2.17290 to 1.73489, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8798 - loss: 2.1312 - val_accuracy: 0.9865 - val_loss: 1.7349\n",
      "Epoch 12/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9375 - loss: 1.7538\n",
      "Epoch 12: val_loss improved from 1.73489 to 1.33083, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9306 - loss: 1.7514 - val_accuracy: 1.0000 - val_loss: 1.3308\n",
      "Epoch 13/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9375 - loss: 1.4356\n",
      "Epoch 13: val_loss improved from 1.33083 to 0.98884, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 1.3694 - val_accuracy: 1.0000 - val_loss: 0.9888\n",
      "Epoch 14/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.9581\n",
      "Epoch 14: val_loss improved from 0.98884 to 0.72793, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9788 - loss: 1.0047 - val_accuracy: 1.0000 - val_loss: 0.7279\n",
      "Epoch 15/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.7395\n",
      "Epoch 15: val_loss improved from 0.72793 to 0.54139, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9476 - loss: 0.8111 - val_accuracy: 1.0000 - val_loss: 0.5414\n",
      "Epoch 16/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.9842\n",
      "Epoch 16: val_loss improved from 0.54139 to 0.40689, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9768 - loss: 0.6742 - val_accuracy: 1.0000 - val_loss: 0.4069\n",
      "Epoch 17/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.4227\n",
      "Epoch 17: val_loss improved from 0.40689 to 0.31410, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9783 - loss: 0.5085 - val_accuracy: 1.0000 - val_loss: 0.3141\n",
      "Epoch 18/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.4247\n",
      "Epoch 18: val_loss improved from 0.31410 to 0.24385, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9821 - loss: 0.4648 - val_accuracy: 1.0000 - val_loss: 0.2438\n",
      "Epoch 19/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.3985\n",
      "Epoch 19: val_loss improved from 0.24385 to 0.19636, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.3756 - val_accuracy: 1.0000 - val_loss: 0.1964\n",
      "Epoch 20/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.2407\n",
      "Epoch 20: val_loss improved from 0.19636 to 0.16214, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.3011 - val_accuracy: 1.0000 - val_loss: 0.1621\n",
      "Epoch 21/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.2352\n",
      "Epoch 21: val_loss improved from 0.16214 to 0.13635, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.2936 - val_accuracy: 1.0000 - val_loss: 0.1363\n",
      "Epoch 22/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.2294\n",
      "Epoch 22: val_loss improved from 0.13635 to 0.11509, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9898 - loss: 0.2474 - val_accuracy: 1.0000 - val_loss: 0.1151\n",
      "Epoch 23/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.2372\n",
      "Epoch 23: val_loss improved from 0.11509 to 0.10106, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9957 - loss: 0.2193 - val_accuracy: 1.0000 - val_loss: 0.1011\n",
      "Epoch 24/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.2638\n",
      "Epoch 24: val_loss improved from 0.10106 to 0.08768, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9927 - loss: 0.2096 - val_accuracy: 1.0000 - val_loss: 0.0877\n",
      "Epoch 25/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.1423\n",
      "Epoch 25: val_loss improved from 0.08768 to 0.07705, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.1641 - val_accuracy: 1.0000 - val_loss: 0.0770\n",
      "Epoch 26/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.2216\n",
      "Epoch 26: val_loss improved from 0.07705 to 0.06508, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9897 - loss: 0.1678 - val_accuracy: 1.0000 - val_loss: 0.0651\n",
      "Epoch 27/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.1373\n",
      "Epoch 27: val_loss improved from 0.06508 to 0.05723, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.1508 - val_accuracy: 1.0000 - val_loss: 0.0572\n",
      "Epoch 28/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.1959\n",
      "Epoch 28: val_loss improved from 0.05723 to 0.05158, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.1376 - val_accuracy: 1.0000 - val_loss: 0.0516\n",
      "Epoch 29/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.1365\n",
      "Epoch 29: val_loss improved from 0.05158 to 0.04657, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9963 - loss: 0.1294 - val_accuracy: 1.0000 - val_loss: 0.0466\n",
      "Epoch 30/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0741\n",
      "Epoch 30: val_loss improved from 0.04657 to 0.04124, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.1123 - val_accuracy: 1.0000 - val_loss: 0.0412\n",
      "Epoch 31/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0847\n",
      "Epoch 31: val_loss improved from 0.04124 to 0.03683, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0919 - val_accuracy: 1.0000 - val_loss: 0.0368\n",
      "Epoch 32/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.1032\n",
      "Epoch 32: val_loss improved from 0.03683 to 0.03241, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.1066 - val_accuracy: 1.0000 - val_loss: 0.0324\n",
      "Epoch 33/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.1047\n",
      "Epoch 33: val_loss improved from 0.03241 to 0.02947, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0929 - val_accuracy: 1.0000 - val_loss: 0.0295\n",
      "Epoch 34/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0553\n",
      "Epoch 34: val_loss improved from 0.02947 to 0.02698, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0695 - val_accuracy: 1.0000 - val_loss: 0.0270\n",
      "Epoch 35/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0827\n",
      "Epoch 35: val_loss improved from 0.02698 to 0.02469, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0662 - val_accuracy: 1.0000 - val_loss: 0.0247\n",
      "Epoch 36/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9375 - loss: 0.1577\n",
      "Epoch 36: val_loss improved from 0.02469 to 0.02268, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9887 - loss: 0.0834 - val_accuracy: 1.0000 - val_loss: 0.0227\n",
      "Epoch 37/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0696\n",
      "Epoch 37: val_loss improved from 0.02268 to 0.02172, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0798 - val_accuracy: 1.0000 - val_loss: 0.0217\n",
      "Epoch 38/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0442\n",
      "Epoch 38: val_loss improved from 0.02172 to 0.02014, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0656 - val_accuracy: 1.0000 - val_loss: 0.0201\n",
      "Epoch 39/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0666\n",
      "Epoch 39: val_loss improved from 0.02014 to 0.01880, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0548 - val_accuracy: 1.0000 - val_loss: 0.0188\n",
      "Epoch 40/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0366\n",
      "Epoch 40: val_loss improved from 0.01880 to 0.01724, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0560 - val_accuracy: 1.0000 - val_loss: 0.0172\n",
      "Epoch 41/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0862\n",
      "Epoch 41: val_loss improved from 0.01724 to 0.01646, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0767 - val_accuracy: 1.0000 - val_loss: 0.0165\n",
      "Epoch 42/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0449\n",
      "Epoch 42: val_loss improved from 0.01646 to 0.01587, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0716 - val_accuracy: 1.0000 - val_loss: 0.0159\n",
      "Epoch 43/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0469\n",
      "Epoch 43: val_loss improved from 0.01587 to 0.01460, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0603 - val_accuracy: 1.0000 - val_loss: 0.0146\n",
      "Epoch 44/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0642\n",
      "Epoch 44: val_loss improved from 0.01460 to 0.01331, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0477 - val_accuracy: 1.0000 - val_loss: 0.0133\n",
      "Epoch 45/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0483\n",
      "Epoch 45: val_loss improved from 0.01331 to 0.01268, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0595 - val_accuracy: 1.0000 - val_loss: 0.0127\n",
      "Epoch 46/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0507\n",
      "Epoch 46: val_loss improved from 0.01268 to 0.01145, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0502 - val_accuracy: 1.0000 - val_loss: 0.0114\n",
      "Epoch 47/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0550\n",
      "Epoch 47: val_loss improved from 0.01145 to 0.01096, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 0.0402 - val_accuracy: 1.0000 - val_loss: 0.0110\n",
      "Epoch 48/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0585\n",
      "Epoch 48: val_loss improved from 0.01096 to 0.01014, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0660 - val_accuracy: 1.0000 - val_loss: 0.0101\n",
      "Epoch 49/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0439\n",
      "Epoch 49: val_loss improved from 0.01014 to 0.00949, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9991 - loss: 0.0420 - val_accuracy: 1.0000 - val_loss: 0.0095\n",
      "Epoch 50/50\n",
      "\u001b[1m 1/19\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0486\n",
      "Epoch 50: val_loss improved from 0.00949 to 0.00861, saving model to best_model.keras\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0363 - val_accuracy: 1.0000 - val_loss: 0.0086\n"
     ]
    }
   ],
   "source": [
    "# Callbacks untuk Early Stopping dan Model Checkpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'best_model.keras',  # Ubah ekstensi file menjadi .keras\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Membuat model\n",
    "model = build_model(X_train.shape[1], len(set(y)))\n",
    "\n",
    "# Melatih model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=16,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 100.00%\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "               Bahagia_Kafe       1.00      1.00      1.00         1\n",
      "             Bahagia_Pantai       1.00      1.00      1.00         1\n",
      "              Bahagia_Rumah       1.00      1.00      1.00         1\n",
      "              Bahagia_Taman       1.00      1.00      1.00         1\n",
      "              Bergairah_Gym       1.00      1.00      1.00         1\n",
      "           Bergairah_Kantor       1.00      1.00      1.00         1\n",
      "  Bersyukur_Kegiatan Sosial       1.00      1.00      1.00         1\n",
      "            Bersyukur_Rumah       1.00      1.00      1.00         1\n",
      "             Bingung_Kampus       1.00      1.00      1.00         1\n",
      "             Bingung_Museum       1.00      1.00      1.00         1\n",
      "       Bingung_Perpustakaan       1.00      1.00      1.00         1\n",
      "            Bingung_Sekolah       1.00      1.00      1.00         1\n",
      "               Cemas_Kantor       1.00      1.00      1.00         1\n",
      "         Cemas_Perpustakaan       1.00      1.00      1.00         1\n",
      "    Cemas_Transportasi Umum       1.00      1.00      1.00         1\n",
      "              Euforis_Event       1.00      1.00      1.00         1\n",
      "              Frustrasi_Gym       1.00      1.00      1.00         1\n",
      "           Frustrasi_Kantor       1.00      1.00      1.00         1\n",
      "Frustrasi_Transportasi Umum       1.00      1.00      1.00         1\n",
      "                 Gemas_Kafe       1.00      1.00      1.00         1\n",
      "                Gemas_Rumah       1.00      1.00      1.00         1\n",
      "             Gembira_Pantai       1.00      1.00      1.00         1\n",
      "              Gembira_Rumah       1.00      1.00      1.00         1\n",
      "               Gugup_Kantor       1.00      1.00      1.00         1\n",
      "    Gugup_Transportasi Umum       1.00      1.00      1.00         1\n",
      "              Kecewa_Kampus       1.00      1.00      1.00         1\n",
      "              Kecewa_Kantor       1.00      1.00      1.00         1\n",
      "            Kecewa_Restoran       1.00      1.00      1.00         1\n",
      "             Kecewa_Sekolah       1.00      1.00      1.00         1\n",
      "                Kesal_Event       1.00      1.00      1.00         1\n",
      "               Kesal_Kantor       1.00      1.00      1.00         1\n",
      "            Kesal_Pertemuan       1.00      1.00      1.00         1\n",
      "                Kesal_Rumah       1.00      1.00      1.00         1\n",
      "                  Malu_Kafe       1.00      1.00      1.00         1\n",
      "                 Malu_Rumah       1.00      1.00      1.00         1\n",
      "               Marah_Kantor       1.00      1.00      1.00         1\n",
      "            Marah_Pertemuan       1.00      1.00      1.00         1\n",
      "             Marah_Restoran       1.00      1.00      1.00         1\n",
      "                Nyaman_Kafe       1.00      1.00      1.00         1\n",
      "               Nyaman_Rumah       1.00      1.00      1.00         1\n",
      "               Nyaman_Taman       1.00      1.00      1.00         1\n",
      "                Optimis_Gym       1.00      1.00      1.00         1\n",
      "             Optimis_Kampus       1.00      1.00      1.00         1\n",
      "             Optimis_Kantor       1.00      1.00      1.00         1\n",
      "               Panik_Kantor       1.00      1.00      1.00         1\n",
      "    Panik_Transportasi Umum       1.00      1.00      1.00         1\n",
      "          Penuh Harapan_Gym       1.00      1.00      1.00         1\n",
      "       Penuh Harapan_Kampus       1.00      1.00      1.00         1\n",
      "       Penuh Harapan_Kantor       1.00      1.00      1.00         1\n",
      "                Puas_Kantor       1.00      1.00      1.00         1\n",
      "                Rindu_Rumah       1.00      1.00      1.00         1\n",
      "               Sedih_Kantor       1.00      1.00      1.00         1\n",
      "      Sedih_Kegiatan Sosial       1.00      1.00      1.00         1\n",
      "                Sedih_Rumah       1.00      1.00      1.00         1\n",
      "                Senyum_Kafe       1.00      1.00      1.00         1\n",
      "               Senyum_Rumah       1.00      1.00      1.00         1\n",
      "        Tenang_Perpustakaan       1.00      1.00      1.00         1\n",
      "               Tenang_Taman       1.00      1.00      1.00         1\n",
      "       Tenang_Tempat Ibadah       1.00      1.00      1.00         1\n",
      "              Terharu_Rumah       1.00      1.00      1.00         1\n",
      "      Terharu_Tempat Ibadah       1.00      1.00      1.00         1\n",
      "        Terinspirasi_Kampus       1.00      1.00      1.00         1\n",
      "        Terinspirasi_Museum       1.00      1.00      1.00         1\n",
      "   Terinspirasi_Studio Seni       1.00      1.00      1.00         1\n",
      "            Terkejut_Kantor       1.00      1.00      1.00         1\n",
      "             Terkejut_Rumah       1.00      1.00      1.00         1\n",
      "             Terluka_Kantor       1.00      1.00      1.00         1\n",
      "              Terluka_Rumah       1.00      1.00      1.00         1\n",
      "             Tersenyum_Kafe       1.00      1.00      1.00         1\n",
      "            Tersenyum_Rumah       1.00      1.00      1.00         1\n",
      "          Tertantang_Kampus       1.00      1.00      1.00         1\n",
      "          Tertantang_Kantor       1.00      1.00      1.00         1\n",
      "            Tertarik_Museum       1.00      1.00      1.00         1\n",
      "       Tertarik_Studio Seni       1.00      1.00      1.00         1\n",
      "\n",
      "                   accuracy                           1.00        74\n",
      "                  macro avg       1.00      1.00      1.00        74\n",
      "               weighted avg       1.00      1.00      1.00        74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluasi model\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Model Accuracy: {score[1]*100:.2f}%\")\n",
    "\n",
    "# Prediksi\n",
    "y_pred = model.predict(X_test).argmax(axis=1)\n",
    "\n",
    "# Pastikan target_names sesuai dengan kelas yang ada di y_test\n",
    "unique_classes = sorted(set(y_test))  # Ambil kelas unik dari y_test\n",
    "target_names = label_encoder.inverse_transform(unique_classes)  # Ambil nama kelas sesuai\n",
    "\n",
    "# Laporan klasifikasi dengan labels yang sesuai\n",
    "print(classification_report(\n",
    "    y_test, \n",
    "    y_pred, \n",
    "    target_names=target_names,\n",
    "    labels=unique_classes\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contoh Prediksi dan Penampilan Pertanyaan:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "Pertanyaan untuk (Sangat Baik, Bersyukur, Kegiatan Sosial):\n",
      "1. Apa yang membuat kamu merasa bersyukur di Kegiatan Sosial?\n",
      "2. Apa yang bisa menyebabkan perasaan bersyukur kamu di Kegiatan Sosial?\n",
      "3. Bagaimana situasi di Kegiatan Sosial mempengaruhi perasaan kamu yang bersyukur?\n",
      "4. Apa langkah yang dapat kamu ambil untuk memperbaiki perasaan sangat buruk di Kegiatan Sosial?\n",
      "5. Bagaimana cara kamu meningkatkan rasa bersyukur dalam kehidupan sehari-hari di Kegiatan Sosial?\n"
     ]
    }
   ],
   "source": [
    "# Fungsi untuk memprediksi dan menampilkan pertanyaan\n",
    "def predict_and_display_questions(level_emosi, tipe_emosi, sumber_emosi):\n",
    "    # Membuat label dari input triplet\n",
    "    label = f\"{tipe_emosi}_{sumber_emosi}\"\n",
    "    \n",
    "    # Cek apakah label ada dalam mapping\n",
    "    if label not in label_to_questions:\n",
    "        print(f\"Tidak ada pertanyaan yang tersedia untuk kombinasi: ({level_emosi}, {tipe_emosi}, {sumber_emosi})\")\n",
    "        return\n",
    "    \n",
    "    # Membuat teks input untuk prediksi\n",
    "    input_text = f\"{level_emosi} {tipe_emosi} {sumber_emosi}\"\n",
    "    processed_text = preprocess_text(input_text)\n",
    "    \n",
    "    # Vektorisasi\n",
    "    vector = vectorizer.transform([processed_text]).toarray()\n",
    "    \n",
    "    # Prediksi\n",
    "    prediction = model.predict(vector).argmax(axis=1)\n",
    "    predicted_label = label_encoder.inverse_transform(prediction)[0]\n",
    "    \n",
    "    # Verifikasi apakah prediksi sesuai dengan input label\n",
    "    if predicted_label != label:\n",
    "        print(f\"Peringatan: Prediksi label ({predicted_label}) tidak sesuai dengan input label ({label}).\")\n",
    "    \n",
    "    # Menampilkan pertanyaan yang relevan\n",
    "    questions = label_to_questions.get(predicted_label, [])\n",
    "    if questions:\n",
    "        print(f\"\\nPertanyaan untuk ({level_emosi}, {tipe_emosi}, {sumber_emosi}):\")\n",
    "        for idx, question in enumerate(questions, 1):\n",
    "            print(f\"{idx}. {question}\")\n",
    "    else:\n",
    "        print(\"Tidak ada pertanyaan yang tersedia untuk label ini.\")\n",
    "\n",
    "# Contoh penggunaan\n",
    "print(\"\\nContoh Prediksi dan Penampilan Pertanyaan:\")\n",
    "# predict_and_display_questions(\"Sangat Buruk\", \"Kecewa\", \"Sekolah\")\n",
    "predict_and_display_questions(\"Sangat Baik\", \"Bersyukur\", \"Kegiatan Sosial\")\n",
    "# predict_and_display_questions(\"Sangat Baik\", \"Penuh Harapan\", \"Kampus\") \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
